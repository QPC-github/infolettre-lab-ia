#+title: Infolettre Lab IA n°6
#+date: 2020-10-05
#+author: Etalab
#+layout: post
#+draft: false

L'infolettre du Lab IA est une lettre d'information mensuelle sur les actualités du Lab IA d'Etalab, *les échanges, expérimentations, rencontres et outils autour de l'usage des données et de l'IA pour améliorer l'action publique*. Elle s’adresse à la communauté du Lab IA : participants aux [[https://www.etalab.gouv.fr/intelligence-artificielle-decouvrez-les-15-nouveaux-projets-selectionnes][AMI IA 1 et 2]], data scientists de l'administration, chercheurs et agents publics intéressés par la science des données et l'IA.

Vous pouvez vous y inscrire depuis [[https://infolettres.etalab.gouv.fr/subscribe/lab-ia@mail.etalab.studio][ce lien]], [[https://etalab.github.io/infolettre-lab-ia/][lire les infolettres précédentes]] et proposer des contenus pour les prochaines éditions.

/Ci-dessous/ : 

- *Zoom sur les projets AMI-IA 2 : Protéger les administrations des cyberattaques (ANSSI)
- Rediffusion : Datadrink de la rentrée et projets data science & IA avec l'INA, Météo France, Etalab et le Ministère du Travail
- Création du Pôle d'Expertise de la Régulation Numérique : Appuyer techniquement les services de l'Etat dans la supervision des plateformes numériques

/Les prochains RDVs du Lab IA d'Etalab/ : 

- Prochain datadrink des datascientists de l'administration le 29 octobre de 16h à 17h ! Programme à venir, pour y présenter votre réflexion ou projet IA, contactez-nous : lab-ia@data.gouv.fr
- L'IA et les métiers du contrôle : Kim Montalibet, datascientist au Lab IA d'Etalab, interviendra lors du [[mailto:https://webikeo.fr/webinar/l-intelligence-artificielle-et-les-metiers-du-controle-opportunites-et-cas-d-usages-dans-les-services-de-l-etat?message=log&redirect=%2Fwebinar%2Fl-intelligence-artificielle-et-les-metiers-du-controle-opportunites-et-cas-d-usages-dans-les-services-de-l-etat%2Flive][webinaire sur les opportunités et cas d'usages dans les services de l'Etat]]. Organisé en partenariat avec la Fing et la préfecture de la région Occitanie, les projets AMI-IA 1 de l'Agence Française de la Biodiversité et de la Direction départementale des territoires et de la mer (DDTM) y présenteront leurs projets. 
- Pour une IA francophone (PIAF) : 685 contributeurs, 9140 questions-réponses annotées aujourd'hui ! L'annotation continue, inscrivez-vous aux [[https://piaf.etalab.studio/agenda/][prochains ateliers en ligne le 13 octobre]. [[https://piaf.etalab.studio/img/TekPiaf.pdf][Ici]], l’amélioration des choix techniques et de l’architecture de la plateforme PIAF en cours.

/L'administration recrute/ :
-	Le nouveau Pôle d’Expertise de la Régulation Numérique recrute ! Les offres seront bientôt publiées, vous pouvez aussi faire acte de candidature spontanée en contactant lucas.verney@finances.gouv.fr et peren.dge@finances.gouv.fr 
-	La Cour des Comptes recrute un data scientist pour renforcer son pôle données [[https://www.place-emploi-public.gouv.fr/offre-emploi/une-data-scientist-au-centre-appui-metier-de-la-cour-des-comptes-reference-2020-462290][ici]]
-	Direction Générale des Finances Publiques (DGFiP), Direction Générale de la Concurrence, de la Consommation et de la Répression des Fraudes (DGCCRF), Direction de la Recherche, des Etudes et des Statistisques (DRES) [[https://www.place-emploi-public.gouv.fr/][recrutent datascientists débutants et confirmés]] : spécialistes en visualisation, traitement des images, animation de réseau, exploitation des données de santé.

/Notre sélection de ressources à visiter/ :
- Jeux de données, réutilisations, outils : [[https://www.data.gouv.fr/fr/posts/les-nouveautes-data-gouv-fr-de-lete-2020/][ les nouveautés data.gouv.fr de l’été 2020]]
-	Ioana Manolescu, directrice scientifique du Lab IA d’Etalab, a présenté à notre équipe les techniques innovantes utilisées pour le fact-checking et le journalisme de données : [[https://pages.saclay.inria.fr/ioana.manolescu/IoanaManolescu-LabIA-23092020.pdf][le support de présentation ici]]
-	Un laboratoire participatif « Location Intelligence4Cities and Regions » est organisé par la Commission Européenne  en anglais le mercredi 14 octobre à 11h30 : plus d’infos [[https://joinup.ec.europa.eu/collection/elise-european-location-interoperability-solutions-e-government/event/participatory-lab-location-intelligence4cities-and-regions][ici]]
-	Pour les datascientists intéressés par le Traitement Automatique du Langage Naturel et anglophones : le « NLP Summit », deux semaines intensive gratuites de formations (pour débutants et datascientists confirmés), un datathon et des discussions en ligne, du 6 au 16 octobre : [[https://www.nlpsummit.org/?utm_source=ben&utm_medium=twitter&utm_campaign=nlpsummit][ici]]
-	« Reconnaissance faciale, ultime avatar du capitalisme de surveillance : quels enjeux pour la démocratie ? » une conférence de l’INRIA avec Asma Mhalla le vendredi 23 octobre [[https://team.inria.fr/steep/seminars/les-conferences-debats-comprendre-et-agir/#conf24][ici]]
-	« Grand projets numériques et défis écologiques : contradictoires, ou nécessaires ? » le mercredi 7 octobre de 19h à 21h30, séminaire grand public organisé par la Chaire Good In Tech [[https://www.goodintech.org/EventDetails.html?anchor=&id=7][ici]]

L'équipe du Lab IA d'Etalab

[[https://etalab.github.io/infolettre-lab-ia/numero-5/][Afficher la version en ligne]] / [[https://infolettres.etalab.gouv.fr/subscribe/lab-ia@mail.etalab.studio][S'inscrire à l'infolettre du Lab IA]] / [[https://infolettres.etalab.gouv.fr/unsubscribe/lab-ia@mail.etalab.studio][Se désinscrire]] 

** Zoom sur les projets AMI-IA 2 : Protéger les administrations des cyberattaques (ANSSI)

[[https://etalab.github.io/infolettre-lab-ia/img/cyber.png]]

Areg Baghinyan, membre de l’équipe porteur du projet IA de l’Agence nationale de la sécurité des systèmes d’information (ANSSI) sélectionné dans le cadre de l’[[https://www.modernisation.gouv.fr/home/ami-intelligence-artificielle-15-nouveaux-laureats-se-saisissent-de-lia-pour-leurs-missions-de-service-public][AMI-IA 2]], partage l’avancée de leur projet IA, qui se terminera d’ici janvier 2021 :

« Notre projet consiste *à identifier les anomalies dans les évènements d’authentification Windows sur des parcs informatiques compromis grâce aux algorithmes de Machine Learning (ML)*. En cas d’attaque informatique sur des Ministères ou des Opérateurs d’Importance Vitale (OIV), l’ANSSI peut être sollicitée pour mener des investigations numériques. Les parcs informatiques grandissent de jour en jour, ce qui rend le travail des investigateurs de plus en plus compliqué. La technique des attaquants évolue et la détection par des méthodes classiques n’est plus adaptée dans certains cas. 

Dans ce projet, nous nous sommes concentrés sur la détection d’anomalie en exploitant les données de certains types d’évènement d’authentification Windows. Ces données d’entrée sont assez complexes en termes d’interprétabilité. Le dataset dispose de plusieurs dizaines de champs. Certains champs sont interprétés de différentes façons selon les types d’événement que l’on traite. Un parc informatique peut disposer de plusieurs centaines de millions d’évènements. En plus des problématiques liées aux détections d’anomalie, il y a donc des problématiques liées à la « scalabilité ». Etant donnée la complexité du problème, il nous est paru essentiel de bien cadrer le périmètre. La problématique a été construite en prenant en compte le dataset choisi.

Comment avons-nous organisé l’immersion métier pour le prestataire ? Dans le contexte de notre projet et de crise sanitaire, nous avons fait face à plusieurs difficultés : 

*Comprendre les choix des analystes et leur expertise métier* 

L’expertise métier est importante dans l‘exploitation de ces données : les croisements choisis entre les différents champs déterminent la cohérence des résultats, l’investigation est en soi complexe pour trouver des informations pertinentes. Pour l’automatiser, il faut comprendre la logique des analystes, que nous avons synthétisée sous forme d’heuristiques pour guider les data scientists à construire un outil pertinent. Chaque heuristique est une problématique précise. Une heuristique prend en entrée une partie du dataset, fait des traitements sur la donnée et génère une sortie. Sur les résultats des heuristiques, on applique un corrélateur pour affiner les résultats et dans certains cas éliminer des faux positifs.

/Exemple : une des heuristiques consiste à détecter des anomalies dans les adresses IP extraites à partir des évènements d’authentification Windows. 
Dans certains types d’évènement Windows, des adresses IP apparaissent durant les interactions des utilisateurs entre les différentes machines. Dans certains types d’attaque, quand un attaquant arrive sur le réseau, son objectif est de rester discret. Il fait donc en sorte d’être vu comme un utilisateur légitime. L’idée est de faire la différence entre un attaquant et un utilisateur légitime. Une des méthodes est de construire une vision légitime du parc et ensuit de remonter les IP marginaux./

L’objectif de ce projet est de *concevoir un outil à destination des analystes* pour qu’ils l’utilisent durant les investigations numériques. Pour mener à bien le projet, plusieurs éléments ont était mis en place : 

-	Nous avons *intégré une experte en investigation numérique dans notre équipe porteuse du projet IA* pour apporter ses connaissances métiers à travers la rédaction des heuristiques, en répondant aux questions métiers des prestataires et en vérifiant les résultats de l’outil développé.
-	Avant la situation pandémique, nous avions décidé qu’un membre du prestataire viendrait travailler physiquement dans nos locaux pour faciliter le contact entre le prestataire et l’équipe projet. De plus, cela aurait permis au prestataire de voir la manière dont les investigateurs travaillent. Cependant cela n’a pas pu avoir lieu. 
-	Nous avons fourni des heuristiques créées à partir des résultats d’investigation sur le dataset fourni. Cette investigation a été effectuée par des méthodes « classiques », qui ne font pas appel à l’IA. Le but étant de trouver au moins les mêmes résultats par des méthodes de ML. Le travail autour de ces heuristiques aont permis au prestataire de mieux cerner le sujet et de comprendre la problématique exprimée. Une fois qu’une certaine maturité aura été atteinte par le prestataire, il devra prendre le recul nécessaire pour trouver la bonne méthode d’approche et de construire un outil modulaire et scalable.

*Fournir des données anonymisées et trouver un équilibre entre suppression d’informations sensibles et informations nécessaires pour les algorithmes*

Une autre difficulté fut de *trouver les données : celles que l’on utilise sont sensibles, on ne peut pas les fournir directement. Un travail d’anonymisation des données a été nécessaire* avant de les partager au prestataire. Nous avons fourni les données en deux phases : dans un premier temps des données publiques qui concernent les authentifications Windows, pour comprendre la logique des communications entre différentes machines. Puis nous avons fourni des données beaucoup plus complètes et anonymisées pour qu’ils puissent commencer à travailler. L’exercice d’anonymisation n’est pas trivial. Il consiste à masquer les informations sensibles tout en gardant la logique et sémantique des évènements, pour permettre à l’algorithme développé de les utiliser correctement.

Par ailleurs, la quantité de données fournie est restreinte. Ceci impacte directement sur le choix de l’algorithme d’apprentissage automatiquee. Très rapidement nous nous sommes tournées vers de l’apprentissage non supervisé. Une fois que quelques briques ont été créées, nous avons commencé à faire des tests sur des jeux de données internes. Nous avons ainsi pu faire de l’amélioration continue pour guider au mieux le prestataire et affiner de plus en plus l’outil pour le faire correspondre au mieux aux besoins. »

Les projets du 2ème Appel à Manifestation d’Intérêt en intelligence artificielle ([[https://www.etalab.gouv.fr/intelligence-artificielle-decouvrez-les-15-nouveaux-projets-selectionnes][projets AMI IA-2]]) se termineront sur la période Novembre 2020-Février 2021. Une première restitution des projets qui se terminent en Novembre se tiendra lors du [[https://www.modernisation.gouv.fr/mois-innovation-publique][Mois de l’Innovation Publique en Novembre]]: stay tuned !


** Rediffusion : Datadrink de la rentrée et projets data science & IA avec l'INA, Météo France, Etalab et le Ministère du Travail

[[https://etalab.github.io/infolettre-lab-ia/img/datadrinksept.jpeg]]

La rediffusion est disponible : [[https://visio.incubateur.net/playback/presentation/2.0/playback.html?meetingId=bfbffc35880da87358915de2c5e5212e15ea0e37-1600954846141][ici]]

Les supports de présentations : 
 
-	[[https://speakerdeck.com/etalabia/20200924-datadrink-ina][« Décrire la représentation des femmes et des hommes dans les JT pendant la crise Covid-19 »]], une approche semi-automatique fondée sur l’analyse des incrustations, par David Doukhan, ingénieur de recherche et coordinateur du projet « Gender Equality Monitor »
-	[[https://speakerdeck.com/etalabia/20200924-datadrink-meteo-net][« MétéoNet, un jeu de données météorologiques en libre accès »]], par Gwennaelle Larvor du Lab IA de Météo France, un jeu de données météo de référence pour les datascientists 
-	[[https://speakerdeck.com/etalabia/20200924-datadrink-opendatascience][« Mettre en avant les jeux de données ouverts de data.gouv.fr grâce à l’IA »]], par Florian Laborde, étudiant à Telecom-Paris et l’ENS Paris-Saclay, en stage à Etalab 
-	[[https://speakerdeck.com/etalabia/20200924-datadrink-dgefp][« Ciblage des contrôles de l’activité partielle »]], par Geoffrey Aldebert, Etalab, et Pierre Vercauteren, Organisation de la direction générale à l’emploi et à la formation professionnelle (DGEFP), Ministère du Travail, sur le travail de récupération des données et l’élaboration d’un tableau de bord pour le suivi d’indicateurs sur l’activité partielle dans le contexte de la crise sanitaire

Pour présenter votre réflexion ou projet IA pour l’action publique au réseau des datascientists de l’administration au *prochain datadrink le jeudi 29 octobre de 16h à 17h30* (10 minutes suivies d’échanges), contactez-nous ici : lab-ia@data.gouv.fr 

** Création du Pôle d'Expertise de la Régulation Numérique : Appuyer techniquement les services de l'Etat dans la supervision des plateformes numériques

[[https://etalab.github.io/infolettre-lab-ia/img/peren.png]]

Un nouveau Service à Compétence Nationale (SCN), le Pôle d’Expertise de la Régulation Numérique (PEReN) a été créé afin d’*appuyer les actions publiques en matière de régulation des plateformes numériques*. Il interviendra en renfort des services de l’État (comme le Ministère de l’Économie, des Finances et de la Relance, le Ministère de la Culture, ou le Ministère de l’Europe et des Affaires Étrangères) et des Autorités administratives indépendantes (comme l’Autorité de la Concurrence, l’ARCEP, la CNIL ou le CSA) en impliquantcontribuant des profils techniques pointus (développeurs, data-scientists) à leurs projets, à des fins d’expertise technique, de collecte de données ou d’analyse d’algorithmes. Le PEReN tisse également des partenariats académiques, notamment avec Inria.

Les travaux du PEReN permettront d’apporter un appui technique supplémentaire sur certains sujets tels que *la compréhension détaillée du fonctionnement des algorithmes utilisés par les grandes plateformes numériques (dont les GAFAM), d’alimenter les réflexions quant aux politiques publiques de régulation des plateformes numériques à mener par des collectes et des analyses de données ainsi qu’intervenir pour tester et auditer certains effets algorithmiques observés sur les grandes plateformes du numérique*. Le PEReN permettra également d’offrir des possibilités de mutualisation de certaines briques techniques déjà utilisées dans ce cadre (/scraping/, etc.).

Trois personnes travaillent d’ores et déjà au PEReN à tisser les partenariats et à développer de premières preuves de concepts et de premières illustrations des compétences disponibles, sur des sujets aussi variés que la publicité en ligne, les locations de meublés de tourisme ou encore les magasins d’applications mobiles. Le Pôle offrira, à terme, une vingtaine de postes techniques (développeurs et data-scientists).

Intéressé par ces thématiques ? Des recrutements sont en cours pour recruter les talents nécessaires au fonctionnement du PEReN ! (CV et lettre de motivation à faire parvenir à peren.dge@finances.gouv.fr)



